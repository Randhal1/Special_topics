{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a44778",
   "metadata": {},
   "source": [
    "# Fourier-Features & Adaptive Sampling PINN\n",
    "\n",
    "This notebook implements two enhancements:\n",
    "\n",
    "1. **Positional Fourier Feature Embedding** (Option 1)\n",
    "2. **Adaptive Collocation Sampling** (Option 2)\n",
    "\n",
    "We solve the 3D, time-dependent Schrödinger equation in an infinite cubic well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95e45f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x105fd0d90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e93e071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Hyperparameters & Fourier Embedding ===\n",
    "L, T = 1.0, 1.0        # domain size and final time\n",
    "D_fourier = 50         # number of random Fourier features\n",
    "omega_feat = 10.0      # frequency scale\n",
    "\n",
    "# Random projection matrix for Fourier features\n",
    "B = torch.randn(D_fourier, 4) * omega_feat\n",
    "\n",
    "def fourier_embed(x, y, z, t):\n",
    "    # x,y,z,t: each [N,1]\n",
    "    X = torch.cat([x, y, z, t], dim=1)          # [N,4]\n",
    "    proj = 2 * np.pi * X @ B.T                  # [N, D_fourier]\n",
    "    return torch.cat([torch.sin(proj), torch.cos(proj), X], dim=1)  # [N, 2*D_fourier+4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961d04bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PINN Architecture (SIREN) ===\n",
    "class SineLayer(nn.Module):\n",
    "    def __init__(self, in_f, out_f, omega_0=30.0):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.linear = nn.Linear(in_f, out_f)\n",
    "        nn.init.uniform_(self.linear.weight, -1/in_f, 1/in_f)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.omega_0 * self.linear(x))\n",
    "\n",
    "class SirenNet(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_layers, out_dim=2, omega_0=30.0):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        # First Sine layer\n",
    "        layers.append(SineLayer(in_dim, hidden_layers[0], omega_0))\n",
    "        # Hidden Sine layers\n",
    "        for i in range(len(hidden_layers)-1):\n",
    "            layers.append(SineLayer(hidden_layers[i], hidden_layers[i+1], omega_0))\n",
    "        # Final linear output\n",
    "        layers.append(nn.Linear(hidden_layers[-1], out_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# input dimension = 2*D_fourier + 4\n",
    "in_dim = 2 * D_fourier + 4\n",
    "hidden = [128, 128, 128]\n",
    "model = SirenNet(in_dim, hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd6ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Schrödinger Residual (with embedding) ===\n",
    "def schrodinger_residual(model, x, y, z, t, V_func, hbar=1.0, m=1.0):\n",
    "    # enable grads on inputs\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    y = y.clone().detach().requires_grad_(True)\n",
    "    z = z.clone().detach().requires_grad_(True)\n",
    "    t = t.clone().detach().requires_grad_(True)\n",
    "    # Fourier-feature embed\n",
    "    X_emb = fourier_embed(x, y, z, t)\n",
    "    psi = model(X_emb)\n",
    "    psi_r, psi_i = psi[:,0:1], psi[:,1:2]\n",
    "\n",
    "    # time derivatives\n",
    "    psi_r_t = autograd.grad(psi_r, t, torch.ones_like(psi_r), create_graph=True)[0]\n",
    "    psi_i_t = autograd.grad(psi_i, t, torch.ones_like(psi_i), create_graph=True)[0]\n",
    "\n",
    "    # spatial Laplacians\n",
    "    def laplacian(u, coord):\n",
    "        grad_u = autograd.grad(u, coord, torch.ones_like(u), create_graph=True)[0]\n",
    "        return autograd.grad(grad_u, coord, torch.ones_like(grad_u), create_graph=True)[0]\n",
    "\n",
    "    lap_r = laplacian(psi_r, x) + laplacian(psi_r, y) + laplacian(psi_r, z)\n",
    "    lap_i = laplacian(psi_i, x) + laplacian(psi_i, y) + laplacian(psi_i, z)\n",
    "\n",
    "    V = V_func(x, y, z)\n",
    "    res_r = hbar * psi_i_t + (hbar**2/(2*m)) * lap_r - V * psi_r\n",
    "    res_i = -hbar * psi_r_t + (hbar**2/(2*m)) * lap_i - V * psi_i\n",
    "    return res_r, res_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd3d7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Sampling Routines ===\n",
    "def sample_domain_pool(N):\n",
    "    x = torch.rand(N,1) * L\n",
    "    y = torch.rand(N,1) * L\n",
    "    z = torch.rand(N,1) * L\n",
    "    t = torch.rand(N,1) * T\n",
    "    return x, y, z, t\n",
    "\n",
    "def sample_collocation_from_pool(model, pool_size, colloc_size):\n",
    "    # sample large pool\n",
    "    xp, yp, zp, tp = sample_domain_pool(pool_size)\n",
    "    with torch.no_grad():\n",
    "        res_r, res_i = schrodinger_residual(model, xp, yp, zp, tp, V_func)\n",
    "        err = torch.sqrt(res_r**2 + res_i**2).flatten()\n",
    "        prob = err / err.sum()\n",
    "        idx = torch.multinomial(prob, colloc_size, replacement=False)\n",
    "    return xp[idx], yp[idx], zp[idx], tp[idx]\n",
    "\n",
    "def sample_initial(N):\n",
    "    x = torch.rand(N,1) * L\n",
    "    y = torch.rand(N,1) * L\n",
    "    z = torch.rand(N,1) * L\n",
    "    t = torch.zeros_like(x)\n",
    "    return x, y, z, t\n",
    "\n",
    "def sample_boundary(N):\n",
    "    faces = []\n",
    "    for x0 in [0.0, L]:\n",
    "        x = torch.full((N,1), x0)\n",
    "        y = torch.rand(N,1) * L\n",
    "        z = torch.rand(N,1) * L\n",
    "        t = torch.rand(N,1) * T\n",
    "        faces.append((x,y,z,t))\n",
    "    for y0 in [0.0, L]:\n",
    "        x = torch.rand(N,1) * L\n",
    "        y = torch.full((N,1), y0)\n",
    "        z = torch.rand(N,1) * L\n",
    "        t = torch.rand(N,1) * T\n",
    "        faces.append((x,y,z,t))\n",
    "    for z0 in [0.0, L]:\n",
    "        x = torch.rand(N,1) * L\n",
    "        y = torch.rand(N,1) * L\n",
    "        z = torch.full((N,1), z0)\n",
    "        t = torch.rand(N,1) * T\n",
    "        faces.append((x,y,z,t))\n",
    "    xb = torch.cat([f[0] for f in faces])\n",
    "    yb = torch.cat([f[1] for f in faces])\n",
    "    zb = torch.cat([f[2] for f in faces])\n",
    "    tb = torch.cat([f[3] for f in faces])\n",
    "    return xb, yb, zb, tb\n",
    "\n",
    "# Potential and initial condition\n",
    "def V_func(x, y, z):\n",
    "    return torch.zeros_like(x)\n",
    "def psi_initial(x, y, z):\n",
    "    return torch.exp(-((x-0.5*L)**2 + (y-0.5*L)**2 + (z-0.5*L)**2)/(0.1**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dcd2cd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m epochs = \u001b[32m2000\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs+\u001b[32m1\u001b[39m):\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# Adaptive collocation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     x_r, y_r, z_r, t_r = \u001b[43msample_collocation_from_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolloc_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# PDE loss\u001b[39;00m\n\u001b[32m     17\u001b[39m     res_r, res_i = schrodinger_residual(model, x_r, y_r, z_r, t_r, V_func)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36msample_collocation_from_pool\u001b[39m\u001b[34m(model, pool_size, colloc_size)\u001b[39m\n\u001b[32m     11\u001b[39m xp, yp, zp, tp = sample_domain_pool(pool_size)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     res_r, res_i = \u001b[43mschrodinger_residual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     err = torch.sqrt(res_r**\u001b[32m2\u001b[39m + res_i**\u001b[32m2\u001b[39m).flatten()\n\u001b[32m     15\u001b[39m     prob = err / err.sum()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mschrodinger_residual\u001b[39m\u001b[34m(model, x, y, z, t, V_func, hbar, m)\u001b[39m\n\u001b[32m     11\u001b[39m psi_r, psi_i = psi[:,\u001b[32m0\u001b[39m:\u001b[32m1\u001b[39m], psi[:,\u001b[32m1\u001b[39m:\u001b[32m2\u001b[39m]\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# time derivatives\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m psi_r_t = \u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi_r\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     15\u001b[39m psi_i_t = autograd.grad(psi_i, t, torch.ones_like(psi_i), create_graph=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[32m0\u001b[39m]\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# spatial Laplacians\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interpreters/xptopics/lib/python3.12/site-packages/torch/autograd/__init__.py:496\u001b[39m, in \u001b[36mgrad\u001b[39m\u001b[34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[39m\n\u001b[32m    492\u001b[39m     result = _vmap_internals._vmap(vjp, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, allow_none_pass_through=\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[32m    493\u001b[39m         grad_outputs_\n\u001b[32m    494\u001b[39m     )\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[32m    506\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[32m    507\u001b[39m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[32m    508\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[32m    509\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Interpreters/xptopics/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# === Training with Adaptive Collocation ===\n",
    "# Hyperparams\n",
    "pool_size = 20000\n",
    "colloc_size = 5000\n",
    "ic_size = 2000\n",
    "bc_size = 2000\n",
    "lambda_ic = 10.0\n",
    "lambda_bc = 10.0\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "epochs = 2000\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # Adaptive collocation\n",
    "    x_r, y_r, z_r, t_r = sample_collocation_from_pool(model, pool_size, colloc_size)\n",
    "    # PDE loss\n",
    "    res_r, res_i = schrodinger_residual(model, x_r, y_r, z_r, t_r, V_func)\n",
    "    loss_pde = (res_r**2 + res_i**2).mean()\n",
    "    # IC loss\n",
    "    x_i, y_i, z_i, t_i = sample_initial(ic_size)\n",
    "    psi0 = psi_initial(x_i, y_i, z_i)\n",
    "    pred0 = model(fourier_embed(x_i,y_i,z_i,t_i))\n",
    "    loss_ic = ((pred0[:,0:1] - psi0)**2 + (pred0[:,1:2])**2).mean()\n",
    "    # BC loss\n",
    "    x_b, y_b, z_b, t_b = sample_boundary(bc_size)\n",
    "    pred_b = model(fourier_embed(x_b,y_b,z_b,t_b))\n",
    "    loss_bc = (pred_b**2).mean()\n",
    "\n",
    "    loss = loss_pde + lambda_ic*loss_ic + lambda_bc*loss_bc\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs} — Total Loss: {loss.item():.3e}  PDE: {loss_pde.item():.3e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34938e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Compare against Analytical Solution ===\n",
    "hbar = 1.0; m = 1.0\n",
    "E111 = (3 * np.pi**2 * hbar**2)/(2*m * L**2)\n",
    "def psi_exact(x, y, z, t):\n",
    "    val = np.sin(np.pi*x/L)*np.sin(np.pi*y/L)*np.sin(np.pi*z/L)\n",
    "    return val * np.exp(-1j * E111 * t / hbar)\n",
    "\n",
    "# evaluate on slice t=0.5, z=L/2\n",
    "t0, z0 = 0.5, L/2\n",
    "n = 50\n",
    "xs = np.linspace(0, L, n)\n",
    "ys = np.linspace(0, L, n)\n",
    "X, Y = np.meshgrid(xs, ys)\n",
    "xf = torch.tensor(X.flatten(), dtype=torch.float32).unsqueeze(1)\n",
    "yf = torch.tensor(Y.flatten(), dtype=torch.float32).unsqueeze(1)\n",
    "zf = torch.full_like(xf, z0)\n",
    "tf = torch.full_like(xf, t0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(fourier_embed(xf,yf,zf,tf)).numpy()\n",
    "psi_r_pred = pred[:,0].reshape(n,n)\n",
    "psi_i_pred = pred[:,1].reshape(n,n)\n",
    "\n",
    "psi_ex = psi_exact(X, Y, z0, t0)\n",
    "psi_r_ex = psi_ex.real\n",
    "psi_i_ex = psi_ex.imag\n",
    "\n",
    "# Plot\n",
    "fig, axs = plt.subplots(2,2, figsize=(10,8))\n",
    "axs[0,0].imshow(psi_r_pred, extent=[0,L,0,L], origin='lower'); axs[0,0].set_title('Pred Re(ψ)')\n",
    "axs[0,1].imshow(psi_r_ex, extent=[0,L,0,L], origin='lower'); axs[0,1].set_title('Exact Re(ψ)')\n",
    "axs[1,0].imshow(psi_i_pred, extent=[0,L,0,L], origin='lower'); axs[1,0].set_title('Pred Im(ψ)')\n",
    "axs[1,1].imshow(psi_i_ex, extent=[0,L,0,L], origin='lower'); axs[1,1].set_title('Exact Im(ψ)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xptopics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
